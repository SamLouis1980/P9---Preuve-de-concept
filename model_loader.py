import os
import logging
import json
from google.cloud import storage
import torch
import torchvision
from transformers import Mask2FormerForUniversalSegmentation
from models_fpn import FPN_Segmenter  # Import du mod√®le FPN

# Configuration du logging
logging.basicConfig(level=logging.DEBUG, format="%(asctime)s - %(levelname)s - %(message)s")

# D√©sactiver CUDA pour forcer le CPU si aucun GPU n'est disponible
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# Chemin de la cl√© GCP
GCP_CREDENTIALS_PATH = "/tmp/gcp_key.json"

def load_gcp_credentials():
    """Charge la cl√© GCP uniquement si elle est n√©cessaire pour t√©l√©charger les mod√®les."""
    try:
        credentials_json = None

        # V√©rifier si une cl√© existe d√©j√† dans l'environnement
        if "GOOGLE_APPLICATION_CREDENTIALS" in os.environ:
            logging.info("‚úÖ Cl√© GCP d√©j√† configur√©e dans GOOGLE_APPLICATION_CREDENTIALS.")
            return  # Rien √† faire, la cl√© est d√©j√† d√©finie

        # V√©rifier si une cl√© est disponible via une variable d'environnement
        if "GCP_CREDENTIALS" in os.environ:
            credentials_json = os.environ["GCP_CREDENTIALS"]
            logging.info("üîë Cl√© GCP d√©tect√©e dans les variables d'environnement.")

        if credentials_json:
            credentials_dict = json.loads(credentials_json) if isinstance(credentials_json, str) else credentials_json

            # Sauvegarder la cl√© dans un fichier temporaire
            with open(GCP_CREDENTIALS_PATH, "w") as f:
                json.dump(credentials_dict, f)

            # D√©finir la variable d‚Äôenvironnement pour Google Cloud
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = GCP_CREDENTIALS_PATH
            logging.info("‚úÖ Cl√© GCP enregistr√©e et utilis√©e dans /tmp/gcp_key.json")
        else:
            logging.warning("‚ö†Ô∏è Aucune cl√© GCP trouv√©e. L'API pourra fonctionner uniquement si la cl√© est d√©j√† configur√©e.")
    
    except json.JSONDecodeError:
        logging.error("‚ùå Erreur de d√©codage JSON dans GCP_CREDENTIALS.")
        raise RuntimeError("Erreur de d√©codage JSON dans GCP_CREDENTIALS.")
    except Exception as e:
        logging.error(f"‚ùå Impossible de charger la cl√© GCP : {e}")
        raise RuntimeError("Erreur de configuration GCP.")

# Charger les credentials GCP si n√©cessaire
load_gcp_credentials()

# Configuration du bucket Google Cloud
BUCKET_NAME = "p8_segmentation_models"
MODEL_PATHS = {
    "fpn": "fpn_best.pth",
    "mask2former": "mask2former_best.pth"
}

MODEL_INPUT_SIZES = {
    "fpn": (512, 512),
    "mask2former": (512, 512)
}

def download_file(bucket_name, source_blob_name, destination_file_name):
    """T√©l√©charge un fichier depuis Google Cloud Storage."""
    try:
        client = storage.Client()
        bucket = client.bucket(bucket_name)
        blob = bucket.blob(source_blob_name)
        blob.download_to_filename(destination_file_name)
        logging.info(f"üì• Fichier t√©l√©charg√© : {destination_file_name}")
    except Exception as e:
        logging.error(f"‚ùå Erreur lors du t√©l√©chargement de {source_blob_name} : {e}")
        raise RuntimeError(f"Impossible de t√©l√©charger {source_blob_name}")

def load_model(model_name="fpn"):
    """Charge un mod√®le de segmentation bas√© sur Torch."""
    model_path = MODEL_PATHS[model_name]
    local_model_path = os.path.join(os.getcwd(), model_path)

    # V√©rifie si le mod√®le est local
    if not os.path.exists(local_model_path):
        logging.info(f"üìå Le mod√®le {model_name} n'est pas trouv√© localement. T√©l√©chargement en cours...")
        download_file(BUCKET_NAME, model_path, local_model_path)

        if not os.path.exists(local_model_path):
            raise RuntimeError(f"‚ùå Le mod√®le {model_name} n'a pas √©t√© correctement t√©l√©charg√©.")

        logging.info(f"‚úÖ Mod√®le {model_name} t√©l√©charg√© avec succ√®s.")

    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        if model_name == "mask2former":
            logging.info("üöÄ Chargement de Mask2Former pr√©-entra√Æn√©...")
            model = Mask2FormerForUniversalSegmentation.from_pretrained(
                "facebook/mask2former-swin-large-cityscapes-semantic"
            ).to(device)
        else:
            logging.info("üöÄ Chargement du mod√®le FPN...")
            model = FPN_Segmenter(num_classes=8).to(device)

        # Charger les poids fine-tun√©s
        model.load_state_dict(torch.load(local_model_path, map_location=device))

        model.eval()
        logging.info(f"‚úÖ Mod√®le {model_name} charg√© avec succ√®s.")
        return model

    except Exception as e:
        logging.error(f"‚ùå Erreur lors du chargement du mod√®le {model_name} : {e}")
        raise RuntimeError(f"Impossible de charger le mod√®le {model_name}")
